# Autonomous_Exploration
Autonomous exploration of a mobile vechicle using frontier_based algorithm for the exploration and RRT/RRT*/A*/Hybrid A* for the move_base. Mobile robot in an unknown environment has to explore the environment autonomously and create a map for it, for which ros package gmapping and a lidar named sick_tim are used. Then frontier_based algorithm would apply a new destination for robot to keep exploring and move_base package generates a viable trajectory from current positon to the destination. Several options are applied when selecting the trajectory generation algorithms including RRT, RRT*, A* and Hybrid A*.
In Gazebo, the localization of the mobile vehicle can be obtained from Gazebo while the encoders are used in the real test. In addition to the encoders, ros package laser_scan_matcher is used for better localization.

# Prerequisite
- ubuntu 18.04
- ROS is installed
- gmapping

# Install
download the code directly, and directory autonomous_exploration is considered as the workspace.    
`git clone https://github.com/HAOLI-TUKL/autonomous_exploration.git`       

# Usage
1. enter the workspace
`cd autonomous_exploration`    

2. compile the workspace
`catkin_make`     

3. source before run
`source devel/setup.bash`  

4. call the launch file to run all the nodes
`roslaunch mycar launch_all.launch`

# Technical Overview
* my_frontier_exploration package generates a destination(frontier) for mobile vehicle in order to approach the boundary between the explorated and unexplorated area. When multiple destinations(frontiers) can be selected, a closest one in the DFS tree would be chosen.
* my_move_base package generates a trajectory from the current position to the destination generated by my_frontier_exploration package. The trajectory can be generated based on RRT/RRT* / A* / Hybrid A*, which can be determined in the launch_all.launch. Then PID controller would be used to have the vehicle follow the trajectory.
* my_car package and my_controller mainly deals with the vehicle model and driver for the simulation in Gazebo.
# Simulation in Gazebo 
<img width="750" height="450" src="https://github.com/HAOLI-TUKL/autonomous_exploration/blob/master/images/simulation.gif"/>  
The video of the simulation can be found :https://www.youtube.com/watch?v=Z0UcYPeM29c  

   
# Test in Mobile Vehicle
<img width="750" height="450" src="https://github.com/HAOLI-TUKL/autonomous_exploration/blob/master/images/lower.gif"/>  


<img width="750" height="450" src="https://github.com/HAOLI-TUKL/autonomous_exploration/blob/master/images/30seconds.gif"/> 
The video of the jetson tx2 test can be found :https://www.youtube.com/watch?v=bSvpSfiEyiM&t=14s    

# Hardwares Introduction

<img width="500" height="650" src="https://github.com/HAOLI-TUKL/autonomous_exploration/blob/master/images/hardware3.png"/> 


# Maintainers
HAO LI leochina2018@163.com     
JIEMING CHEN




# References
Yamauchi, Brian. “A frontier-based approach for autonomous exploration.” Proceedings 1997 IEEE International Symposium on Computational Intelligence in Robotics and Automation CIRA'97. 'Towards New Computational Principles for Robotics and Automation' (1997): 146-151.


https://github.com/HAOLI-TUKL/autonomous_exploration  

https://github.com/zwkcoding/autonomous_exploration  

https://github.com/HanwenCao/Frontier_Exploration  

https://github.com/RobustFieldAutonomyLab/em_exploration  

https://github.com/bigmb/Autonomous-Navigation-and-Exploration  

https://github.com/RobustFieldAutonomyLab/turtlebot_exploration_3d  

https://github.com/tpepels/turtlebot_slam  

